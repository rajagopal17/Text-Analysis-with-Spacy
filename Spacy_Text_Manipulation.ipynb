{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy_Text_Manipulation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10GFDV44pi7ZZOjZQ8XQO_sfKE8_vNIuF",
      "authorship_tag": "ABX9TyPVd8iVortgYzh086/VL0Hk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajagopal17/Text-Analysis-with-Spacy/blob/master/Spacy_Text_Manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fU1jllxdKKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.rc('font', size=14)\n",
        "sns.set(style='white')\n",
        "sns.set(style='whitegrid', color_codes=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVtp2O0Yc2TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim,pprint\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
        "from gensim.models import Phrases\n",
        "#from gensim.models.word2vec import sentences\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim import corpora, models,similarities\n",
        "from gensim.models import LdaModel\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gesRSeykdCP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals\n",
        "import spacy\n",
        "from spacy.tokens import doc\n",
        "nlp=spacy.load('en')\n",
        "import en_core_web_sm\n",
        "#nlp=en_core_web_md.load()\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "punctuations=string.punctuation"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMtUphaAdVHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02kbrRUGUueK",
        "colab_type": "text"
      },
      "source": [
        "#To convert entire text into a list of tokens\n",
        "If text is converted to list of tokens, then it cannot be converted to sentences because list doesn't has the sent function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re7gJ2UPdj4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To convert entire text into tokens within a list\n",
        "doc_file2=list(nlp(open('/content/drive/My Drive/Python/arnav.txt').read()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCDSS3V-VtQi",
        "colab_type": "text"
      },
      "source": [
        "#If Text is wrapped with nlp without list, then it can be converted to sentences using '.sents'\n",
        "\n",
        "The below code will output tokenized text. \n",
        "To view tokens we need to add code  \"for x in doc_file, print(x)\n",
        "This text contains all features of Spacy, we can get x.pos_, x.text, etc..\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmQp36xoU6R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_file3=nlp(open('/content/drive/My Drive/Python/arnav.txt').read())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCLpJXHRV8J0",
        "colab_type": "text"
      },
      "source": [
        "#Function to convert text data into sentences. \n",
        "\n",
        "This Function will convert the text into sentences and sentences to tokens\n",
        "But we need to filter out stop-words & punctuations and put it into a single list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lf6fnEzmSel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_text_sent (xtext):\n",
        "  for sentx in xtext.sents:\n",
        "    print(list(sentx))\n",
        "\n",
        "get_sentx= convert_text_sent(doc_file3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPzFVmAUJWeZ",
        "colab_type": "text"
      },
      "source": [
        "#Alternate way to convert text data into sentences with cleaning using Gensim\n",
        "\n",
        "\n",
        "1.   Convert data into '.sents' format before converting into list\n",
        "2.   Wrap the '.sents' data with list\n",
        "3.   Then input the [data.sents] format into the gensim function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFs9OcOEBDtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####    Convert data into nlp format\n",
        "\n",
        "doc_file4= nlp(open('/content/drive/My Drive/Python/arnav.txt').read())\n",
        "\n",
        "####.  Convert the nlp data to '.sents' and wrap it with a list\n",
        "\n",
        "doc_file5 = list(doc_file4.sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6A0H9FJMsxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####    Now input doc_file5 to below function. This function generates a list for each sentence\n",
        "\n",
        "def sent_to_words(datax):\n",
        "    for y in datax:\n",
        "        yield(gensim.utils.simple_preprocess(str(y),deacc=True,min_len=2))\n",
        "\n",
        "###    wrap all the lists into another list  \n",
        "\n",
        "edata_input=sent_to_words(doc_file5)\n",
        "data_input=list(sent_to_words(doc_file5))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzNJpTDo9EAG",
        "colab_type": "text"
      },
      "source": [
        "#  Converting text data in a list into list of sentences\n",
        "   - here we are not using Spacy or Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbiW5FFa8N3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7b6a6b14-638c-4584-9987-4b820b0771d8"
      },
      "source": [
        "documents = [\"The Saudis are preparing a report that will acknowledge that\", \n",
        "             \"Saudi journalist Jamal Khashoggi's death was the result of an\", \n",
        "             \"interrogation that went wrong, one that was intended to lead\", \n",
        "             \"to his abduction from Turkey, according to two sources.\"]\n",
        "sent_list =[]\n",
        "for x in documents:\n",
        "  sent_list.append(x.split())\n",
        "\n",
        "print(sent_list)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['The', 'Saudis', 'are', 'preparing', 'a', 'report', 'that', 'will', 'acknowledge', 'that'], ['Saudi', 'journalist', 'Jamal', \"Khashoggi's\", 'death', 'was', 'the', 'result', 'of', 'an'], ['interrogation', 'that', 'went', 'wrong,', 'one', 'that', 'was', 'intended', 'to', 'lead'], ['to', 'his', 'abduction', 'from', 'Turkey,', 'according', 'to', 'two', 'sources.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEN6uaZ09Eaa",
        "colab_type": "text"
      },
      "source": [
        "## Converting text data in a list into list of sentences using Gensim - with preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZniQsJxR9Lc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gensim_list = [simple_preprocess(doc) for doc in documents]\n",
        "gensim_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Si21yI-IJG",
        "colab_type": "text"
      },
      "source": [
        "#  Different methods of converting text data which is in string format into sentences using SPACY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK7gghoDwAeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str_text=\" The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmx5QeL1_gNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Just tokenizing the text using SPACY\n",
        "k=nlp(str_text)\n",
        "tok_text =([x.text for x in k if x.is_stop==False and x.is_punct==False])\n",
        "tok_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az1mlAOh_54K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "29c81a74-0967-4208-f317-2c22cd6983cf"
      },
      "source": [
        "# Converting the string text into a list of sentences\n",
        "v=[]\n",
        "for x in k.sents:\n",
        "  v.append(list(x))\n",
        "print(v)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ , The, amount, of, calorie, your, body, requires, to, stay, fit, is, not, fulfilled, by, this, food, .], [For, instance, ,, foods, like, French, fries, ,, burgers, ,, candy, ,, and, cookies, ,, all, have, high, amounts, of, sugar, and, fats, .], [Therefore, ,, this, can, result, in, long, -, term, illnesses, like, diabetes, and, high, blood, pressure, .], [This, may, also, result, in, kidney, failure]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "203n5MojAzTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5926eae5-6271-4d63-d862-d401a0ed62c0"
      },
      "source": [
        "#Converting the string text into a  string of single list of sentences\n",
        "\n",
        "c=[]\n",
        "for x in k.sents:\n",
        "  c.append(str(x))\n",
        "print(c)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' The amount of calorie your body requires to stay fit is not fulfilled by this food.', 'For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats.', 'Therefore, this can result in long-term illnesses like diabetes and high blood pressure.', 'This may also result in kidney failure']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZP6ZY5vBFtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "65ea9204-ad11-4286-b567-9ab3aa8dcc29"
      },
      "source": [
        "# Converting the single list of string sentence from above into list of sentences using gensim\n",
        "gen = [simple_preprocess(x) for x in c]\n",
        "gen"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the',\n",
              "  'amount',\n",
              "  'of',\n",
              "  'calorie',\n",
              "  'your',\n",
              "  'body',\n",
              "  'requires',\n",
              "  'to',\n",
              "  'stay',\n",
              "  'fit',\n",
              "  'is',\n",
              "  'not',\n",
              "  'fulfilled',\n",
              "  'by',\n",
              "  'this',\n",
              "  'food'],\n",
              " ['for',\n",
              "  'instance',\n",
              "  'foods',\n",
              "  'like',\n",
              "  'french',\n",
              "  'fries',\n",
              "  'burgers',\n",
              "  'candy',\n",
              "  'and',\n",
              "  'cookies',\n",
              "  'all',\n",
              "  'have',\n",
              "  'high',\n",
              "  'amounts',\n",
              "  'of',\n",
              "  'sugar',\n",
              "  'and',\n",
              "  'fats'],\n",
              " ['therefore',\n",
              "  'this',\n",
              "  'can',\n",
              "  'result',\n",
              "  'in',\n",
              "  'long',\n",
              "  'term',\n",
              "  'illnesses',\n",
              "  'like',\n",
              "  'diabetes',\n",
              "  'and',\n",
              "  'high',\n",
              "  'blood',\n",
              "  'pressure'],\n",
              " ['this', 'may', 'also', 'result', 'in', 'kidney', 'failure']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}